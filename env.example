# Environment Variables for QA Agent

# ===== LLM Provider Selection =====
# Choose your LLM provider: openai, google (gemini)
LLM_PROVIDER=openai

# ===== OpenAI Settings =====
OPENAI_API_KEY=your-openai-api-key-here
LLM_MODEL=gpt-4.1-mini
LLM_TEMPERATURE=0.2

# ===== Google Gemini Settings =====
# Uncomment to use Gemini (much cheaper: $0.075/M input vs $2.50/M for GPT-4.1)
# GOOGLE_API_KEY=your-google-api-key-here
# GEMINI_MODEL=gemini-2.5-flash
# Pricing: gemini-2.5-flash: $0.075/M input, $0.30/M output (33x cheaper!)
#          gemini-2.5-pro:   $1.25/M input,  $5.00/M output (2x cheaper!)

# LangGraph Settings (optional - defaults shown)
MAX_STEPS=50
MAX_RETRIES=3

# Browser Provider Selection
BROWSER_PROVIDER=chrome  # Options: "onkernal" or "chrome"

# Chrome Settings (only used when BROWSER_PROVIDER=chrome)
CHROME_EXECUTABLE_PATH=  # Leave empty to auto-detect Chrome/Chromium

# Port Settings (shared by both providers)
CDP_PORT=9222  # CDP port (will auto-detect conflicts)
STREAMING_PORT=8080  # Streaming port (will auto-detect conflicts)

# OnKernal Browser Settings (only used when BROWSER_PROVIDER=onkernal)
KERNEL_CDP_HOST=localhost
KERNEL_CDP_PORT=9222  # Deprecated: use CDP_PORT instead

# Browser Settings (optional - defaults shown)
HEADLESS=False

# Logging (optional - defaults shown)
LOG_LEVEL=INFO